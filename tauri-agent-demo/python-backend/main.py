from fastapi import FastAPI, HTTPException, Response
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
import json
from typing import List, Optional
from datetime import datetime

from models import (
    LLMConfig, LLMConfigCreate, LLMConfigUpdate,
    ChatMessage, ChatMessageCreate,
    ChatSession, ChatSessionCreate, ChatSessionUpdate,
    ChatRequest, ChatResponse, ExportRequest
)
from database import db
from llm_client import create_llm_client
from message_processor import message_processor

# Agent framework imports
from agents.executor import create_agent_executor
from agents.base import AgentStep
from tools.builtin import register_builtin_tools
from tools.base import ToolRegistry

app = FastAPI(title="Tauri Agent Chat Backend")

# å…è®¸è·¨åŸŸ
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Register builtin tools
register_builtin_tools()

# ==================== åŸºç¡€è·¯ç”± ====================

@app.get("/")
def read_root():
    return {"status": "FastAPI is running!", "version": "2.0"}

# ==================== LLM é…ç½®ç®¡ç† ====================

@app.get("/configs", response_model=List[LLMConfig])
def get_configs():
    """è·å–æ‰€æœ‰ LLM é…ç½®"""
    return db.get_all_configs()

@app.get("/configs/default", response_model=LLMConfig)
def get_default_config():
    """è·å–é»˜è®¤é…ç½®"""
    config = db.get_default_config()
    if not config:
        # å¦‚æœæ²¡æœ‰é»˜è®¤é…ç½®ï¼Œè¿”å›ç¬¬ä¸€ä¸ªé…ç½®
        configs = db.get_all_configs()
        if configs:
            return configs[0]
        raise HTTPException(status_code=404, detail="æ²¡æœ‰å¯ç”¨çš„é…ç½®")
    return config

@app.get("/configs/{config_id}", response_model=LLMConfig)
def get_config(config_id: str):
    """è·å–æŒ‡å®šé…ç½®"""
    config = db.get_config(config_id)
    if not config:
        raise HTTPException(status_code=404, detail="é…ç½®ä¸å­˜åœ¨")
    return config

@app.post("/configs", response_model=LLMConfig)
def create_config(config: LLMConfigCreate):
    """åˆ›å»ºæ–°é…ç½®"""
    return db.create_config(config)

@app.put("/configs/{config_id}", response_model=LLMConfig)
def update_config(config_id: str, update: LLMConfigUpdate):
    """æ›´æ–°é…ç½®"""
    config = db.update_config(config_id, update)
    if not config:
        raise HTTPException(status_code=404, detail="é…ç½®ä¸å­˜åœ¨")
    return config

@app.delete("/configs/{config_id}")
def delete_config(config_id: str):
    """åˆ é™¤é…ç½®"""
    # æ£€æŸ¥æ˜¯å¦æœ‰ä¼šè¯ä½¿ç”¨è¯¥é…ç½®
    sessions = db.get_all_sessions()
    if any(s.config_id == config_id for s in sessions):
        raise HTTPException(status_code=400, detail="è¯¥é…ç½®æ­£åœ¨è¢«ä¼šè¯ä½¿ç”¨ï¼Œæ— æ³•åˆ é™¤")
    
    if db.delete_config(config_id):
        return {"success": True}
    raise HTTPException(status_code=404, detail="é…ç½®ä¸å­˜åœ¨")

# ==================== ä¼šè¯ç®¡ç† ====================

@app.get("/sessions", response_model=List[ChatSession])
def get_sessions():
    """è·å–æ‰€æœ‰ä¼šè¯"""
    return db.get_all_sessions()

@app.get("/sessions/{session_id}", response_model=ChatSession)
def get_session(session_id: str):
    """è·å–æŒ‡å®šä¼šè¯"""
    session = db.get_session(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
    return session

@app.post("/sessions", response_model=ChatSession)
def create_session(session: ChatSessionCreate):
    """åˆ›å»ºæ–°ä¼šè¯"""
    # éªŒè¯é…ç½®æ˜¯å¦å­˜åœ¨
    config = db.get_config(session.config_id)
    if not config:
        raise HTTPException(status_code=404, detail="æŒ‡å®šçš„é…ç½®ä¸å­˜åœ¨")
    return db.create_session(session)

@app.put("/sessions/{session_id}", response_model=ChatSession)
def update_session(session_id: str, update: ChatSessionUpdate):
    """æ›´æ–°ä¼šè¯"""
    session = db.update_session(session_id, update)
    if not session:
        raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
    return session

@app.delete("/sessions/{session_id}")
def delete_session(session_id: str):
    """åˆ é™¤ä¼šè¯"""
    if db.delete_session(session_id):
        return {"success": True}
    raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

@app.get("/sessions/{session_id}/messages", response_model=List[ChatMessage])
def get_session_messages(session_id: str, limit: Optional[int] = None):
    """è·å–ä¼šè¯çš„æ¶ˆæ¯å†å²"""
    session = db.get_session(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
    return db.get_session_messages(session_id, limit)

# ==================== èŠå¤©åŠŸèƒ½ ====================

@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """
    å‘é€èŠå¤©æ¶ˆæ¯
    
    æµç¨‹ï¼š
    1. è·å–æˆ–åˆ›å»ºä¼šè¯
    2. è·å–é…ç½®
    3. é¢„å¤„ç†ç”¨æˆ·æ¶ˆæ¯
    4. è·å–å†å²æ¶ˆæ¯
    5. è°ƒç”¨ LLM API
    6. åå¤„ç†å“åº”
    7. ä¿å­˜æ¶ˆæ¯
    8. è¿”å›ç»“æœ
    """
    try:
        # 1. å¤„ç†ä¼šè¯
        if request.session_id:
            session = db.get_session(request.session_id)
            if not session:
                raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        else:
            # åˆ›å»ºæ–°ä¼šè¯
            config_id = request.config_id
            if not config_id:
                default_config = db.get_default_config()
                if not default_config:
                    configs = db.get_all_configs()
                    if not configs:
                        raise HTTPException(status_code=400, detail="æ²¡æœ‰å¯ç”¨çš„é…ç½®ï¼Œè¯·å…ˆåˆ›å»ºé…ç½®")
                    config_id = configs[0].id
                else:
                    config_id = default_config.id
            
            session = db.create_session(ChatSessionCreate(
                title="æ–°å¯¹è¯",
                config_id=config_id
            ))
        
        # 2. è·å–é…ç½®
        config = db.get_config(session.config_id)
        if not config:
            raise HTTPException(status_code=404, detail="é…ç½®ä¸å­˜åœ¨")
        
        # 3. é¢„å¤„ç†ç”¨æˆ·æ¶ˆæ¯
        processed_message = message_processor.preprocess_user_message(request.message)
        
        # 4. ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
        user_msg = db.create_message(ChatMessageCreate(
            session_id=session.id,
            role="user",
            content=processed_message
        ))
        
        # 5. è·å–å†å²æ¶ˆæ¯å¹¶æ„å»º LLM è¯·æ±‚
        history = db.get_session_messages(session.id, limit=20)
        # è½¬æ¢ä¸º LLM API æ ¼å¼
        history_for_llm = [
            {"role": msg.role, "content": msg.content}
            for msg in history[:-1]  # æ’é™¤åˆšåˆšæ·»åŠ çš„ç”¨æˆ·æ¶ˆæ¯
        ]
        
        # æ„å»ºå‘é€ç»™ LLM çš„æ¶ˆæ¯
        llm_messages = message_processor.build_messages_for_llm(
            user_message=processed_message,
            history=history_for_llm,
            system_prompt="ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„AIåŠ©æ‰‹ã€‚"
        )
        
        # æ„å»ºå®Œæ•´çš„è¯·æ±‚æ•°æ®ï¼ˆç”¨äºdebugï¼‰
        raw_request_data = {
            "model": config.model,
            "messages": llm_messages,
            "temperature": config.temperature,
            "max_tokens": config.max_tokens,
            "api_type": config.api_type
        }
        
        # 6. è°ƒç”¨ LLM API
        llm_client = create_llm_client(config)
        llm_result = await llm_client.chat(llm_messages)
        
        # æå–å†…å®¹å’ŒåŸå§‹å“åº”
        llm_response = llm_result["content"]
        raw_response_data = llm_result["raw_response"]
        
        # 7. åå¤„ç†å“åº”
        processed_response = message_processor.postprocess_llm_response(llm_response)
        
        # 8. ä¿å­˜åŠ©æ‰‹æ¶ˆæ¯ï¼ˆåŒ…å«åŸå§‹æ•°æ®ï¼‰
        assistant_msg = db.create_message(ChatMessageCreate(
            session_id=session.id,
            role="assistant",
            content=processed_response,
            raw_request=raw_request_data,
            raw_response=raw_response_data
        ))
        
        # 9. è‡ªåŠ¨æ›´æ–°ä¼šè¯æ ‡é¢˜ï¼ˆå¦‚æœæ˜¯ç¬¬ä¸€æ¡æ¶ˆæ¯ï¼‰
        if session.message_count == 0:
            # ä½¿ç”¨ç”¨æˆ·ç¬¬ä¸€æ¡æ¶ˆæ¯çš„å‰20ä¸ªå­—ç¬¦ä½œä¸ºæ ‡é¢˜
            title = processed_message[:20] + ("..." if len(processed_message) > 20 else "")
            db.update_session(session.id, ChatSessionUpdate(title=title))
        
        return ChatResponse(
            reply=processed_response,
            session_id=session.id,
            message_id=assistant_msg.id
        )
    
    except HTTPException:
        raise
    except Exception as e:
        print(f"èŠå¤©é”™è¯¯: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {str(e)}")

@app.post("/chat/stream")
async def chat_stream(request: ChatRequest):
    """æµå¼èŠå¤©æ¥å£ - ä½¿ç”¨SSEé€ä¸ªè¿”å›ç”Ÿæˆçš„æ–‡æœ¬ç‰‡æ®µ"""
    try:
        # 1. å¤„ç†ä¼šè¯
        if request.session_id:
            session = db.get_session(request.session_id)
            if not session:
                raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        else:
            config_id = request.config_id if request.config_id else db.get_all_configs()[0].id
            session = db.create_session(ChatSessionCreate(
                title="æ–°å¯¹è¯",
                config_id=config_id
            ))
        
        # 2. è·å–é…ç½®
        config = db.get_config(session.config_id)
        if not config:
            raise HTTPException(status_code=404, detail="é…ç½®ä¸å­˜åœ¨")
        
        # 3. é¢„å¤„ç†ç”¨æˆ·æ¶ˆæ¯
        processed_message = message_processor.preprocess_user_message(request.message)
        
        # 4. å…ˆè·å–å†å²å¹¶æ„å»ºæ¶ˆæ¯ï¼ˆåœ¨ä¿å­˜ç”¨æˆ·æ¶ˆæ¯ä¹‹å‰ï¼‰
        history = db.get_session_messages(session.id, limit=20)
        history_for_llm = [
            {"role": msg.role, "content": msg.content}
            for msg in history
        ]
        
        llm_messages = message_processor.build_messages_for_llm(
            user_message=processed_message,
            history=history_for_llm,
            system_prompt="ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„AIåŠ©æ‰‹ã€‚"
        )
        
        raw_request_data = {
            "model": config.model,
            "messages": llm_messages,
            "temperature": config.temperature,
            "max_tokens": config.max_tokens,
            "stream": True,
            "api_type": config.api_type
        }
        
        # ç°åœ¨ä¿å­˜ç”¨æˆ·æ¶ˆæ¯ï¼ŒåŒ…å«raw_request
        user_msg = db.create_message(ChatMessageCreate(
            session_id=session.id,
            role="user",
            content=processed_message,
            raw_request=raw_request_data
        ))
        
        # 5. æµå¼ç”Ÿæˆå‡½æ•°
        async def generate():
            # ç«‹å³å‘é€session_idå’Œuser_message_id
            yield f"data: {json.dumps({'session_id': session.id, 'user_message_id': user_msg.id})}\n\n"
            
            full_response = ""
            
            try:
                llm_client = create_llm_client(config)
                
                async for chunk in llm_client.chat_stream(llm_messages):
                    full_response += chunk
                    # ä¿®å¤ï¼šä½¿ç”¨çœŸå®æ¢è¡Œç¬¦ï¼Œä¸æ˜¯è½¬ä¹‰å­—ç¬¦
                    yield f"data: {json.dumps({'content': chunk}, ensure_ascii=False)}\n\n"
                
                processed_response = message_processor.postprocess_llm_response(full_response)
                
                # æµå¼ç»“æŸåä¿å­˜åŠ©æ‰‹æ¶ˆæ¯ï¼ˆåªä¿å­˜raw_responseï¼‰
                assistant_msg = db.create_message(ChatMessageCreate(
                    session_id=session.id,
                    role="assistant",
                    content=processed_response,
                    raw_response={
                        "content": processed_response,
                        "model": config.model,
                        "finish_reason": "stop"
                    }
                ))
                
                yield f"data: {json.dumps({'done': True, 'message_id': assistant_msg.id})}\n\n"
                
            except Exception as e:
                if full_response:
                    db.create_message(ChatMessageCreate(
                        session_id=session.id,
                        role="assistant",
                        content=full_response + "\n\n[æµå¼ä¸­æ–­]",
                        metadata={"error": str(e), "partial": True}
                    ))
                
                yield f"data: {json.dumps({'error': str(e)})}\n\n"
        
        return StreamingResponse(
            generate(),
            media_type="text/event-stream",
            headers={"Cache-Control": "no-cache", "Connection": "keep-alive"}
        )
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ==================== å¯¼å‡ºåŠŸèƒ½ ====================

@app.post("/export")
def export_chat_history(request: ExportRequest):
    """å¯¼å‡ºèŠå¤©å†å²"""
    try:
        if request.session_id:
            # å¯¼å‡ºå•ä¸ªä¼šè¯
            session = db.get_session(request.session_id)
            if not session:
                raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
            sessions = [session]
        else:
            # å¯¼å‡ºæ‰€æœ‰ä¼šè¯
            sessions = db.get_all_sessions()
        
        export_data = []
        for session in sessions:
            messages = db.get_session_messages(session.id)
            config = db.get_config(session.config_id)
            
            session_data = {
                "session": {
                    "id": session.id,
                    "title": session.title,
                    "created_at": session.created_at,
                    "config": {
                        "name": config.name if config else "æœªçŸ¥",
                        "model": config.model if config else "æœªçŸ¥"
                    }
                },
                "messages": [
                    {
                        "role": msg.role,
                        "content": msg.content,
                        "timestamp": msg.timestamp
                    }
                    for msg in messages
                ]
            }
            export_data.append(session_data)
        
        # æ ¹æ®æ ¼å¼å¯¼å‡º
        if request.format == "json":
            content = json.dumps(export_data, ensure_ascii=False, indent=2)
            media_type = "application/json"
            filename = f"chat_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        elif request.format == "txt":
            lines = []
            for session_data in export_data:
                lines.append(f"========== {session_data['session']['title']} ==========")
                lines.append(f"åˆ›å»ºæ—¶é—´: {session_data['session']['created_at']}")
                lines.append(f"é…ç½®: {session_data['session']['config']['name']} ({session_data['session']['config']['model']})")
                lines.append("")
                for msg in session_data['messages']:
                    role_name = "ç”¨æˆ·" if msg['role'] == "user" else "åŠ©æ‰‹"
                    lines.append(f"[{msg['timestamp']}] {role_name}:")
                    lines.append(msg['content'])
                    lines.append("")
                lines.append("\n")
            content = "\n".join(lines)
            media_type = "text/plain"
            filename = f"chat_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        
        elif request.format == "markdown":
            lines = []
            for session_data in export_data:
                lines.append(f"# {session_data['session']['title']}")
                lines.append(f"\n**åˆ›å»ºæ—¶é—´:** {session_data['session']['created_at']}")
                lines.append(f"**é…ç½®:** {session_data['session']['config']['name']} ({session_data['session']['config']['model']})")
                lines.append("\n---\n")
                for msg in session_data['messages']:
                    role_name = "ğŸ§‘ ç”¨æˆ·" if msg['role'] == "user" else "ğŸ¤– åŠ©æ‰‹"
                    lines.append(f"## {role_name}")
                    lines.append(f"*{msg['timestamp']}*\n")
                    lines.append(msg['content'])
                    lines.append("\n")
                lines.append("\n---\n")
            content = "\n".join(lines)
            media_type = "text/markdown"
            filename = f"chat_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        
        else:
            raise HTTPException(status_code=400, detail="ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼")
        
        return Response(
            content=content,
            media_type=media_type,
            headers={"Content-Disposition": f"attachment; filename={filename}"}
        )
    
    except HTTPException:
        raise
    except Exception as e:
        print(f"å¯¼å‡ºé”™è¯¯: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å¯¼å‡ºæ—¶å‡ºé”™: {str(e)}")

# ==================== Agent Chat (Streaming) ====================

@app.post("/chat/agent/stream")
async def chat_agent_stream(request: ChatRequest):
    """
    Agentæ¨¡å¼çš„æµå¼å¯¹è¯
    
    æ”¯æŒï¼š
    - Simple agent (ä¼ ç»Ÿå¯¹è¯)
    - ReAct agent (å¸¦å·¥å…·çš„æ¨ç†-è¡ŒåŠ¨å¾ªç¯)
    - æµå¼è¿”å›thought, action, observation, answeræ­¥éª¤
    """
    try:
        # 1. å¤„ç†ä¼šè¯
        if request.session_id:
            session = db.get_session(request.session_id)
            if not session:
                raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        else:
            # åˆ›å»ºæ–°ä¼šè¯
            config_id = request.config_id or db.get_default_config().id
            session = db.create_session(ChatSessionCreate(
                title="æ–°å¯¹è¯",
                config_id=config_id
            ))
        
        # 2. è·å–é…ç½®
        config = db.get_config(session.config_id)
        if not config:
            raise HTTPException(status_code=404, detail="LLMé…ç½®ä¸å­˜åœ¨")
        
        # 3. é¢„å¤„ç†ç”¨æˆ·æ¶ˆæ¯
        processed_message = message_processor.preprocess_user_message(request.message)
        
        # 4. ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
        user_msg = db.create_message(ChatMessageCreate(
            session_id=session.id,
            role="user",
            content=processed_message
        ))
        
        # 5. è·å–å†å²æ¶ˆæ¯
        history = db.get_session_messages(session.id, limit=20)
        history_for_llm = [
            {"role": msg.role, "content": msg.content}
            for msg in history[:-1]  # æ’é™¤åˆšæ·»åŠ çš„ç”¨æˆ·æ¶ˆæ¯
        ]
        
        # 6. ç¡®å®šAgentç±»å‹ (sessionçº§åˆ«æˆ–requestçº§åˆ«override)
        agent_type = request.agent_type_override if hasattr(request, 'agent_type_override') else getattr(session, 'agent_type', 'simple')
        
        # 7. è·å–å¯ç”¨å·¥å…·
        tools = ToolRegistry.get_all()
        
        # 8. åˆ›å»ºLLMå®¢æˆ·ç«¯
        llm_client = create_llm_client(config)
        
        # 9. åˆ›å»ºAgentæ‰§è¡Œå™¨
        try:
            executor = create_agent_executor(
                agent_type=agent_type,
                llm_client=llm_client,
                tools=tools,
                max_iterations=5  # ReAct max iterations
            )
        except ValueError as e:
            raise HTTPException(status_code=400, detail=str(e))
        
        # 10. æ‰§è¡ŒAgentå¹¶æµå¼è¿”å›
        async def event_generator():
            sequence = 0
            final_answer = None
            assistant_msg_id = None
            
            try:
                # First create a placeholder assistant message
                temp_assistant_msg = db.create_message(ChatMessageCreate(
                    session_id=session.id,
                    role="assistant",
                    content=""  # Will be updated with final answer
                ))
                assistant_msg_id = temp_assistant_msg.id
                
                # Stream agent execution
                async for step in executor.run(
                    user_input=processed_message,
                    history=history_for_llm,
                    session_id=session.id
                ):
                    # Save step to database
                    db.save_agent_step(
                        message_id=assistant_msg_id,
                        step_type=step.step_type,
                        content=step.content,
                        sequence=sequence,
                        metadata=step.metadata
                    )
                    
                    # Save tool calls separately
                    if step.step_type == "action" and "tool" in step.metadata:
                        db.save_tool_call(
                            message_id=assistant_msg_id,
                            tool_name=step.metadata["tool"],
                            tool_input=step.metadata.get("input", ""),
                            tool_output=""  # Will be filled by observation
                        )
                    
                    # Track final answer
                    if step.step_type == "answer":
                        final_answer = step.content
                    
                    # Stream to frontend
                    yield f"data: {json.dumps(step.to_dict())}\n\n"
                    
                    sequence += 1
                
                # Update assistant message with final answer
                if final_answer and assistant_msg_id:
                    # Update message content
                    conn = db.get_connection()
                    cursor = conn.cursor()
                    cursor.execute('''
                        UPDATE chat_messages
                        SET content = ?
                        WHERE id = ?
                    ''', (final_answer, assistant_msg_id))
                    conn.commit()
                    conn.close()
                
                # Send done signal
                yield f"data: {json.dumps({'done': True, 'session_id': session.id})}\n\n"
                
            except Exception as e:
                # Send error
                error_step = AgentStep(
                    step_type="error",
                    content=f"Agentæ‰§è¡Œå¤±è´¥: {str(e)}",
                    metadata={"error": str(e)}
                )
                yield f"data: {json.dumps(error_step.to_dict())}\n\n"
        
        return StreamingResponse(
            event_generator(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no"  # Disable nginx buffering
            }
        )
    
    except HTTPException:
        raise
    except Exception as e:
        print(f"AgentèŠå¤©é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"AgentèŠå¤©æ—¶å‡ºé”™: {str(e)}")

# ==================== Tools Management ====================

@app.get("/tools")
def get_tools():
    """è·å–æ‰€æœ‰å¯ç”¨å·¥å…·"""
    tools = ToolRegistry.get_all()
    return [tool.to_dict() for tool in tools]

if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨ FastAPI æœåŠ¡å™¨...")
    print("ğŸ“ æ”¯æŒçš„ LLM: OpenAI, æ™ºè°±AI, Deepseek")
    print("ğŸ’¾ æ•°æ®åº“: SQLite (chat_app.db)")
    uvicorn.run(app, host="127.0.0.1", port=8000)
