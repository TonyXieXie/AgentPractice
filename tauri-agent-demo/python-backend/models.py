from pydantic import BaseModel, Field
from typing import Optional, Dict, Any, Literal
from datetime import datetime

# LLM API ç±»å‹
LLMApiType = Literal["openai", "zhipu", "deepseek"]

# LLM é…ç½®æ¨¡å‹
class LLMConfig(BaseModel):
    id: Optional[str] = None
    name: str
    api_type: LLMApiType
    api_key: str
    base_url: Optional[str] = None
    model: str
    temperature: float = Field(default=0.7, ge=0.0, le=2.0)
    max_tokens: int = Field(default=2000, ge=1, le=32000)
    is_default: bool = False
    created_at: Optional[str] = None
    # ğŸ”¥ Reasoning å‚æ•°ï¼ˆç”¨äº O1/GPT-5 ç³»åˆ—æ¨¡å‹ï¼‰
    reasoning_effort: Optional[Literal["none", "minimal", "low", "medium", "high", "xhigh"]] = "medium"
    reasoning_summary: Optional[Literal["auto", "concise", "detailed"]] = "detailed"

class LLMConfigCreate(BaseModel):
    name: str
    api_type: LLMApiType
    api_key: str
    base_url: Optional[str] = None
    model: str
    temperature: float = 0.7
    max_tokens: int = 2000
    is_default: bool = False
    # ğŸ”¥ Reasoning å‚æ•°ï¼ˆç”¨äº O1/GPT-5 ç³»åˆ—æ¨¡å‹ï¼‰
    reasoning_effort: Optional[Literal["none", "minimal", "low", "medium", "high", "xhigh"]] = "medium"
    reasoning_summary: Optional[Literal["auto", "concise", "detailed"]] = "detailed"

class LLMConfigUpdate(BaseModel):
    name: Optional[str] = None
    api_key: Optional[str] = None
    base_url: Optional[str] = None
    model: Optional[str] = None
    temperature: Optional[float] = None
    max_tokens: Optional[int] = None
    is_default: Optional[bool] = None
    # ğŸ”¥ Reasoning å‚æ•°ï¼ˆç”¨äº O1/GPT-5 ç³»åˆ—æ¨¡å‹ï¼‰
    reasoning_effort: Optional[Literal["none", "minimal", "low", "medium", "high", "xhigh"]] = None
    reasoning_summary: Optional[Literal["auto", "concise", "detailed"]] = None

# èŠå¤©æ¶ˆæ¯æ¨¡å‹
class ChatMessage(BaseModel):
    id: Optional[int] = None
    session_id: str
    role: Literal["user", "assistant", "system"]
    content: str
    timestamp: Optional[str] = None
    metadata: Optional[Dict[str, Any]] = None
    raw_request: Optional[Dict[str, Any]] = None  # LLMåŸå§‹è¯·æ±‚
    raw_response: Optional[Dict[str, Any]] = None  # LLMåŸå§‹å“åº”

class ChatMessageCreate(BaseModel):
    session_id: str
    role: Literal["user", "assistant", "system"]
    content: str
    metadata: Optional[Dict[str, Any]] = None
    raw_request: Optional[Dict[str, Any]] = None  # LLMåŸå§‹è¯·æ±‚
    raw_response: Optional[Dict[str, Any]] = None  # LLMåŸå§‹å“åº”

# ä¼šè¯æ¨¡å‹
class ChatSession(BaseModel):
    id: Optional[str] = None
    title: str
    config_id: str
    created_at: Optional[str] = None
    updated_at: Optional[str] = None
    message_count: Optional[int] = 0

class ChatSessionCreate(BaseModel):
    title: str = "æ–°å¯¹è¯"
    config_id: str

class ChatSessionUpdate(BaseModel):
    title: Optional[str] = None

# API è¯·æ±‚/å“åº”æ¨¡å‹
class ChatRequest(BaseModel):
    message: str
    session_id: Optional[str] = None
    config_id: Optional[str] = None

class ChatResponse(BaseModel):
    reply: str
    session_id: str
    message_id: int

class ExportRequest(BaseModel):
    session_id: Optional[str] = None  # None è¡¨ç¤ºå¯¼å‡ºæ‰€æœ‰ä¼šè¯
    format: Literal["json", "txt", "markdown"] = "json"
